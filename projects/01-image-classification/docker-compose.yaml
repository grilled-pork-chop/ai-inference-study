services:
  triton:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: triton-inference-server
    command: tritonserver --model-repository=/models --disable-auto-complete-config
    ports:
      - "8001:8001"  # HTTP
      - "8002:8002"  # GRPC
    volumes:
      - ./model:/models
    environment:
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    networks:
      - inference-net

  api:
    build: .
    container_name: api
    ports:
      - "8000:8000"
    environment:
      - TRITON_HOST=triton
      - TRITON_HTTP_PORT=8001
      - LOG_LEVEL=info
      - MAX_IMAGE_SIZE=10485760
      # - ALLOWED_EXTENSIONS=jpg,jpeg,png,webp
    depends_on:
      triton:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    volumes:
      - ./app:/app/app
    networks:
      - inference-net
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/triton.rules.yml:/etc/prometheus/triton.rules.yml
    networks:
      - inference-net
    depends_on:
      - api

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - inference-net
    depends_on:
      - prometheus

networks:
  inference-net:
    driver: bridge

volumes:
  prometheus-data:
  grafana-data: